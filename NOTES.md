[TOC]

# 1. 数据探索



## 1.1 缺失数据处理



## 1.2 不均衡样本 imbalance

样本不均衡会出现对样本数较多的类别过拟合，对较少的类别欠拟合，即总是将样本分类到样本数较多的分类类别。

常用的采样方法有以下几种：

### 1.2.1 随机欠采样 undersampling

随机从数量大的类别中选出一部分样本与数量小的类别样本组成新的训练集。

优点：平衡数据的同时减少了数据量，加速了训练；

缺点：数据减少会影响模型的特征学习能力和泛化能力；

### 1.2.2 随机过采样 oversampling

将数量小的类别样本复制k次，与数量大的类别样本组成新的训练集。

优点：相对于undersampling



# 2. 特征工程

选取特征时候要具有实际的物理意义，能够共多方面表达或者阐述一个事情（从不同角度）

## 2.1 特征归一化 normalization

### 2.1.1 线性函数归一化 max-min normalization

将数据映射到[0, 1]的范围内，公式如下：

$$x_{norm} = (X - X_{min}) / (X_{max} - X_{min})$$

### 2.1.2 零均值归一化 z-score nomalization

将数据映射到均值为0，标准差为1的分布上，公式如下：

$$z = (x - \mu) / \sigma$$

对于梯度下降求解模型，如线性回归、逻辑回归、SVM、神经网络等，归一化会对收敛速度产生影响，在通常情况下需要归一化，但是对于决策树模型类的，一般不需要。



## 2.2 类别型特征的转换



